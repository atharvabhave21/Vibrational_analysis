{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### libraries ################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ functions ################\n",
    "def scale_plot_size(factor=3.0):\n",
    "    default_figsize = mpl.rcParamsDefault['figure.figsize']\n",
    "    mpl.rcParams['figure.figsize'] = [val*factor for val in default_figsize]\n",
    "scale_plot_size(1.5)\n",
    "\n",
    "def rms(df):\n",
    "    return np.sqrt(df.dot(df)/df.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### reading file & preprocessing ##########\n",
    "header = [\"Hr\", \"Min\",\"Sec\",\"uSec\", \"X\",\"Y\"]\n",
    "\n",
    "training_set_path = os.path.expanduser('~/Vibrational_analysis/data/IEEE_dataset/Learning_set/Bearing1_1')\n",
    "\n",
    "dirList = os.listdir(os.path.expanduser(training_set_path))\n",
    "dirList.sort()\n",
    "n = 0\n",
    "\n",
    "for sets in dirList: \n",
    "    if sets == 'temp_00001.csv':\n",
    "        break\n",
    "    df = pd.read_csv(training_set_path+\"/\"+sets, header=None)\n",
    "    df.columns = header\n",
    "    data = np.array(df,np.float64)\n",
    "    columnx = data[:,4]\n",
    "    columny = data[:,5]\n",
    "\n",
    "    if n==0 :\n",
    "        x = columnx\n",
    "        y = columny\n",
    "\n",
    "        kurtx = stats.kurtosis(columnx)\n",
    "        kurty = stats.kurtosis(columny)\n",
    "\n",
    "        rmsx = rms(columnx)\n",
    "        rmsy = rms(columny)\n",
    "        \n",
    "        n = 1\n",
    "    else:\n",
    "        x= np.append(x,columnx)\n",
    "        y= np.append(y,columny)\n",
    "\n",
    "        kurtx = np.append(kurtx,stats.kurtosis(columnx))\n",
    "        kurty = np.append(kurty,stats.kurtosis(columny))\n",
    "\n",
    "        rmsx = np.append(rmsx,rms(columnx))\n",
    "        rmsy = np.append(rmsy,rms(columny))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### defining input variables ###############\n",
    "n = kurtx.shape[0]\n",
    "\n",
    "X = np.vstack ((kurtx,kurty,rmsx,rmsy))\n",
    "threshold_1 = int(n*0.50)\n",
    "threshold_2 = int(n*0.25)\n",
    "\n",
    "output = np.arange (n-1,-1,-1,dtype=np.float64)\n",
    "output = np.reshape(output,(kurtx.shape[0],1))\n",
    "\n",
    "Y = np.where( output>threshold_1 , 0 , 1 )\n",
    "Y[-threshold_2:] = 2\n",
    "\n",
    "Xnm = preprocessing.normalize(X)\n",
    "Xnm = Xnm.transpose()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xnm, Y, test_size=0.2, random_state=69)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
